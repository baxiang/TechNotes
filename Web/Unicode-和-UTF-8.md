### ASCII
In the older days of computing, ASCII code was used to represent characters. The English language has only 26 alphabets and a few other special characters and symbols.
åœ¨æ—©æœŸçš„è®¡ç®—æœºæ—¶ä»£ä¸­ï¼ŒASCIIç ç”¨äºè¡¨ç¤º26ä¸ªè‹±è¯­å­—æ¯ä»¥åŠä¸€äº›ç‰¹æ®Šçš„å­—ç¬¦å’Œç¬¦å·ã€‚
The table below provides the ASCII characters and their corresponding Decimal and Hex values.
ä¸‹è¡¨å±•ç¤ºäº†ASCIIå­—ç¬¦å¯¹åº”çš„åè¿›åˆ¶å€¼å’Œåå…­è¿›åˆ¶å€¼ã€‚
![ascii codes](http://upload-images.jianshu.io/upload_images/143845-d3f25e7c69272c8f.gif?imageMogr2/auto-orient/strip)

As you can infer from the above table, the ASCII values can be represented from 0 to 127 in the decimal number system. Lets look at the binary representation of 0 and 127 in 8 bit bytes.
é€šè¿‡ä¸Šè¡¨æˆ‘ä»¬å¾—çŸ¥ï¼Œé€šè¿‡0åˆ°127å¯ä»¥ä»£è¡¨ASCIIå€¼ä»»æ„å€¼ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å¦‚ä½•é€šè¿‡çš„8ä½çš„äºŒè¿›åˆ¶æ¥è¡¨ç¤º0åˆ°127ã€‚
0 is represented as

![0 in binary](http://upload-images.jianshu.io/upload_images/143845-b8d8074f97fcea18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

127 is represented as

![127 in binary](http://upload-images.jianshu.io/upload_images/143845-5ed6d53f2f6c51b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

It can be inferred from the above binary representation that decimal values 0 to 127 can be represented using 7 bits leaving the 8th bit free.
å®é™…ä¸Šæˆ‘ä»¬åªæ˜¯ç”¨äº†7ä¸ªå­—èŠ‚å°±è¡¨ç¤ºé™¤äº†0åˆ°127 ç¬¬å…«ä½æ˜¯ç©ºä½™çš„
This is where things started getting messy.

People came up with different ways of using the remaining eight bit which represented decimal values from 128 to 255 and collisions started to happen. For instance the decimal value 182 was used by the Vietnamese to represent the Vietnamese alphabet á» whereas the same value 182 was used by the Indians to represent the Hindi alphabetÂ *à¤˜*. So if an email written by an Indian contains the alphabetÂ *à¤˜*Â and if it is read by a person in Vietnam it would appear asÂ *á»*. Cleary not the intended way to appear.

This is whereÂ [Unicode](http://www.unicode.org/)Â character set came to save the day.
è¿™å°±æ˜¯Unicodeäº§ç”Ÿçš„åŸå› 
### Unicodeå’Œç ç‚¹

Unicode character set mapped each character in the world to a unique number. This ensured that there are no collisions between alphabets of different languages. These numbers are platform independent.
Unicodeå­—ç¬¦é›†å°†ä¸–ç•Œä¸Šçš„æ¯ä¸ªå­—ç¬¦å’Œä¸€ä¸ªæƒŸä¸€çš„æ•°å­—ç›¸å¯¹åº”ã€‚ä»¥æ­¤è§£å†³ä¸åŒè¯­è¨€çš„å­—æ¯ä¹‹é—´çš„å†²çªã€‚
**These unique numbers are called as code points in the unicode terminology.**

Lets see how they are referred.

The latin characterÂ *á¹*Â is referred using the code point

```
U+1E4D  

```

**U+**Â denotes unicode andÂ **1E4D**Â is the hexadecimal value assigned to the character á¹

The English alphabetÂ **A**Â is represented asÂ **U+0041**

Please visitÂ [http://www.unicode.org/charts/](http://www.unicode.org/charts/)Â to know the code points for all languages and alphabets of the world
**U +**è¡¨ç¤ºunicodeï¼Œ**1E4D**æ˜¯åˆ†é…ç»™å­—ç¬¦hexçš„åå…­è¿›åˆ¶å€¼
è‹±æ–‡å­—æ¯**A**è¡¨ç¤ºä¸º**U + 0041**
è¯·è®¿é—®[http://www.unicode.org/charts/](http://www.unicode.org/charts/)ï¼Œäº†è§£ä¸–ç•Œä¸Šæ‰€æœ‰è¯­è¨€å’Œå­—æ¯çš„ä»£ç ç‚¹

### utf - 8ç¼–ç 

Now that we know what is unicode and how each alphabet in the world is assigned to a unique code point, we need a way to represent these code points in the computer's memory. This is where character encodings come into the picture. One such encoding scheme is UTF-8.
æ—¢ç„¶æˆ‘ä»¬å·²çŸ¥é“unicodeï¼Œä»¥åŠä¸–ç•Œä¸Šæ¯ä¸ªå­—æ¯æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„çš„ç ç‚¹çš„ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥åœ¨è®¡ç®—æœºå†…å­˜ä¸­çš„è¡¨ç¤ºè¿™äº›ç ç‚¹ã€‚è¿™å°±æ˜¯å­—ç¬¦ç¼–ç çš„ç”¨æ­¦ä¹‹åœ°ã€‚å…¶ä¸­ä¸€ç§ç¼–ç æ–¹æ¡ˆå°±æ˜¯UTF-8ã€‚

UTF-8 encoding is a variable sized encoding scheme to represent unicode code points in memory. Variable sized encoding means the code points are represented using 1, 2, 3 or 4 bytes depending on their size
UTF-8ç¼–ç æ˜¯ä¸€ç§å­—èŠ‚å¤§å°å¯å˜çš„ç¼–ç æ–¹æ¡ˆï¼Œç”¨äºè¡¨ç¤ºå†…å­˜ä¸­çš„unicodeç¼–ç ç‚¹ã€‚å¯å˜å­—èŠ‚é•¿åº¦ç¼–ç æ„å‘³ç€ç ç‚¹æ ¹æ®å¤§å°ä½¿ç”¨1ã€2ã€3æˆ–4ä¸ªå­—èŠ‚è¡¨ç¤ºã€‚

##### UTF-8 1 byte encoding

AÂ **1 byte encoding**Â is identified by the presence of 0 in the first bit.

![UTF-8 1 byte encoding](http://upload-images.jianshu.io/upload_images/143845-579d92884dcf8606.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

The English alphabetÂ **A**Â has unicode code pointÂ **U+0041**. It's binary representation isÂ **1000001**.

A is represented in UTF-8 encoding as
**01000001**

**The red 0 bit indicates that 1 byte encoding is used and the remaining bits represent the code point**

##### UTF-8 2 byte encoding

The latin alphabetÂ **Ã±**Â with code pointÂ **U+00F1**Â has binary valueÂ **11110001**. This value is larger than the maximum value that can be represented using 1 byte encoding format and hence this alphabet will be represented using UTF-8 2 byte encoding.
æ‹‰ä¸å­—æ¯Ã±ä¸ä»£ç ç‚¹U + 00F1å…·æœ‰äºŒè¿›åˆ¶å€¼11110001ã€‚è¯¥å€¼å¤§äºå¯ä»¥ä½¿ç”¨1å­—èŠ‚ç¼–ç æ ¼å¼è¡¨ç¤ºçš„æœ€å¤§å€¼ï¼Œå› æ­¤è¯¥å­—æ¯è¡¨å°†ä½¿ç”¨UTF-8 2å­—èŠ‚ç¼–ç è¡¨ç¤ºã€‚

2 byte encoding is identified by the presence of the bit sequenceÂ **110**Â in the first bit andÂ **10**Â in the second bit.
é€šè¿‡ç¬¬ä¸€ä½ä¸­çš„ä½åºåˆ—110å’Œç¬¬äºŒä½ä¸­çš„10çš„å­˜åœ¨æ¥è¯†åˆ«2å­—èŠ‚ç¼–ç ã€‚

![image](http://upload-images.jianshu.io/upload_images/143845-a0c3189f9f370c2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

The binary value of the unicode code pointÂ **U+00F1**Â isÂ **1111 0001**. Filling these bits in the 2 byte encoding format, we get the UTF-8 2 byte encoding representation ofÂ **Ã±**Â shown below. The filling is done starting with the least significant bit of the code point being mapped to the least significant bit of the second byte.

**11000011Â 10110001**

The binary digits in blueÂ **11110001**Â represent the code point U+00F1's binary value and the ones in red are the 2 byte encoding identifiers. The black coloured zeros are used to fill up the empty bits in the byte.

##### UTF-8 3 byte encoding

The latin characterÂ **á¹**Â with code pointÂ **U+1E4D**Â is be represented using 3 byte encoding as it is larger than the maximum value that can be represented using 2 byte encoding.

A 3 byte encoding is identified by the presence of the bit sequenceÂ **1110 in the first byte and 10 in the second and third bytes.**

![image](http://upload-images.jianshu.io/upload_images/143845-8012533ae1b0c6d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

The binary value for the hex code pointÂ **0x1E4D**Â isÂ **1111001001101**. Filling these bits in the above encoding format gives us the UTF-8 3 byte encoding representation ofÂ **á¹**Â show below. The filling is done starting with the least significant bit of the code point mapped to the least significant of the third byte.
**11100001Â 10111001Â 10001101**
The red bits indicate 3 byte encoding, the black ones are filler bits and the blues represent the code point.

#### UTF-8 4 byte encoding

The Emoji ğŸ˜­ has unicode code pointÂ **U+1F62D**. This is bigger than the maximum value that can be represented using 3 byte encoding and hence will be represented using 4 byte encoding.

4 byte encoding is identified by the presence ofÂ **11110**Â in the first byte andÂ **10**Â in the subsequent second, third and fourth bytes.

![image](http://upload-images.jianshu.io/upload_images/143845-bea45b6a8d5718c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

The binary representation ofÂ **U+1F62D**Â isÂ **11111011000101101**. Filling these bits in the above encoding format gives us the UTF-8 4 byte encoding of ğŸ˜­. The least significant bit of the code point is mapped to the least significant bit of the fourth byte and so on.

**11110000Â 10011111Â 10011000Â 10101101**

The red bits identify the 4 byte encoding format, the blue ones are the actual code point and the black ones are the filler bits.

### UTF-16 Encoding

UTF-16 encoding is a variable byte encoding scheme which uses either 2 bytes or 4 bytes to represent unicode code points. Most of the characters for all modern languages are represented using 2 bytes.

The latin alphabetÂ **Ã±**Â with code pointÂ **U+00F1**Â and with binary valueÂ **11110001**Â is represented in UTF-16 encoding as
**00000000Â 11110001**
The above representation is in Big Endian Byte Order mode(Most significant bit first).
UTF-16ç¼–ç æ˜¯ä¸€ç§å¯å˜å­—èŠ‚ç¼–ç æ–¹æ¡ˆï¼Œå®ƒä½¿ç”¨2ä¸ªå­—èŠ‚æˆ–4ä¸ªå­—èŠ‚æ¥è¡¨ç¤ºunicodeä»£ç ç‚¹ã€‚æ‰€æœ‰ç°ä»£è¯­è¨€çš„å¤§å¤šæ•°å­—ç¬¦éƒ½ä½¿ç”¨2ä¸ªå­—èŠ‚è¡¨ç¤ºã€‚

æ‹‰ä¸å­—æ¯Ã±ï¼Œä»£ç ç‚¹ä¸ºU + 00F1ï¼ŒäºŒè¿›åˆ¶å€¼ä¸º11110001ï¼Œä»¥UTF-16ç¼–ç è¡¨ç¤ºä¸º
### UTF-32 Encoding

UTF-32 encoding is a fixed byte encoding scheme and it uses 4 bytes to represent all code points.

The English alphabet A has unicode code point U+0041\. It's binary representation isÂ **1000001**.
UTF-32ç¼–ç æ˜¯å›ºå®šå­—èŠ‚ç¼–ç æ–¹æ¡ˆï¼Œå®ƒä½¿ç”¨4ä¸ªå­—èŠ‚æ¥è¡¨ç¤ºæ‰€æœ‰ä»£ç ç‚¹ã€‚
è‹±æ–‡å­—æ¯Aå…·æœ‰unicodeä»£ç ç‚¹U + 0041ã€‚å®ƒçš„äºŒè¿›åˆ¶è¡¨ç¤ºæ˜¯1000001ã€‚
Its represented in UTF-32 encoding as shown below,

**00000000 00000000 00000000 01000001**

The blue bits are the binary representation of the code point. The above assumes Big Endian Byte order mode.
Thats if for character sets and encoding.
